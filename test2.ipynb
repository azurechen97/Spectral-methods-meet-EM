{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_table(\"data/rte_crowd.txt\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = pd.read_table(\"data/rte_truth.txt\", header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data):\n",
    "    X = np.array(data)\n",
    "    rows, _ = X.shape\n",
    "    n,m,k = np.max(np.array(data), axis=0)\n",
    "    labels = np.zeros((m,n),dtype=np.int64)-1\n",
    "    for r in range(rows):\n",
    "        labels[X[r,1]-1,X[r,0]-1] = X[r,2]-1\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 164 2\n"
     ]
    }
   ],
   "source": [
    "n,m,k = np.max(np.array(data),axis=0)\n",
    "print(n,m,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = transform_data(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0,  1, ..., -1, -1, -1],\n",
       "       [ 1,  0,  0, ...,  1,  0,  1],\n",
       "       [ 1,  0,  1, ..., -1, -1, -1],\n",
       "       ...,\n",
       "       [-1, -1, -1, ..., -1, -1, -1],\n",
       "       [-1, -1, -1, ..., -1, -1, -1],\n",
       "       [-1, -1, -1, ..., -1, -1, -1]], dtype=int64)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = np.array([i % 3 for i in range(m)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "groups = np.random.randint(3, size=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_estimated = get_confusion_matrix(k, labels, groups=groups,sym=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 50\n",
    "truth_new = truth[truth[0].isin(data[data[1] == i+1][0])]\n",
    "pred_new = data[data[1] == i+1][data[data[1] == i+1][0].isin(truth_new[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>189</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>191</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>192</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>195</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>196</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>197</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>198</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>199</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>202</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>205</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>206</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>207</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>748</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>749</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>751</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>752</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>753</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>754</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>755</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>756</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>757</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>758</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>759</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>761</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>762</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>763</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>764</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>765</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1\n",
       "187  188  1\n",
       "188  189  2\n",
       "189  190  1\n",
       "190  191  2\n",
       "191  192  2\n",
       "192  193  2\n",
       "193  194  1\n",
       "194  195  1\n",
       "195  196  2\n",
       "196  197  2\n",
       "197  198  2\n",
       "198  199  2\n",
       "199  200  1\n",
       "200  201  2\n",
       "201  202  2\n",
       "202  203  1\n",
       "203  204  1\n",
       "204  205  2\n",
       "205  206  2\n",
       "206  207  2\n",
       "745  746  1\n",
       "746  747  1\n",
       "747  748  2\n",
       "748  749  2\n",
       "749  750  2\n",
       "750  751  1\n",
       "751  752  2\n",
       "752  753  1\n",
       "753  754  2\n",
       "754  755  1\n",
       "755  756  2\n",
       "756  757  1\n",
       "757  758  2\n",
       "758  759  2\n",
       "759  760  1\n",
       "760  761  2\n",
       "761  762  1\n",
       "762  763  1\n",
       "763  764  2\n",
       "764  765  1"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>188</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886</th>\n",
       "      <td>189</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>190</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>191</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>192</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>193</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>194</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>195</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>196</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>197</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>198</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>199</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>200</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>201</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>202</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>203</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>204</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>205</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>206</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>207</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7455</th>\n",
       "      <td>746</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7465</th>\n",
       "      <td>747</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7475</th>\n",
       "      <td>748</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7485</th>\n",
       "      <td>749</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7495</th>\n",
       "      <td>750</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7505</th>\n",
       "      <td>751</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7515</th>\n",
       "      <td>752</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7525</th>\n",
       "      <td>753</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>754</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7545</th>\n",
       "      <td>755</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7555</th>\n",
       "      <td>756</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7565</th>\n",
       "      <td>757</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7575</th>\n",
       "      <td>758</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7585</th>\n",
       "      <td>759</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7595</th>\n",
       "      <td>760</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7605</th>\n",
       "      <td>761</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7615</th>\n",
       "      <td>762</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7625</th>\n",
       "      <td>763</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7635</th>\n",
       "      <td>764</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7645</th>\n",
       "      <td>765</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0   1  2\n",
       "1876  188  51  1\n",
       "1886  189  51  2\n",
       "1896  190  51  1\n",
       "1906  191  51  2\n",
       "1916  192  51  2\n",
       "1926  193  51  2\n",
       "1936  194  51  1\n",
       "1946  195  51  1\n",
       "1956  196  51  1\n",
       "1966  197  51  1\n",
       "1976  198  51  2\n",
       "1986  199  51  2\n",
       "1996  200  51  1\n",
       "2006  201  51  1\n",
       "2016  202  51  1\n",
       "2026  203  51  1\n",
       "2036  204  51  2\n",
       "2046  205  51  2\n",
       "2056  206  51  2\n",
       "2066  207  51  1\n",
       "7455  746  51  1\n",
       "7465  747  51  1\n",
       "7475  748  51  2\n",
       "7485  749  51  1\n",
       "7495  750  51  2\n",
       "7505  751  51  1\n",
       "7515  752  51  1\n",
       "7525  753  51  1\n",
       "7535  754  51  2\n",
       "7545  755  51  2\n",
       "7555  756  51  2\n",
       "7565  757  51  1\n",
       "7575  758  51  2\n",
       "7585  759  51  1\n",
       "7595  760  51  1\n",
       "7605  761  51  1\n",
       "7615  762  51  1\n",
       "7625  763  51  1\n",
       "7635  764  51  2\n",
       "7645  765  51  1"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = confusion_matrix(pred_new[2],truth_new[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88235, 0.3913 ],\n",
       "       [0.11765, 0.6087 ]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(C / np.sum(C, axis=0)[np.newaxis, :],5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95657, 0.34086],\n",
       "       [0.04343, 0.65914]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(C_estimated[i],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zg = get_Zg(k, labels, groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.03389831],\n",
       "        [0.05084746, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.03389831, 0.        , 0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , 0.01694915, 0.        ],\n",
       "        [0.        , 0.        , 0.01694915, 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.01694915, 0.01694915, 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        , 0.03389831],\n",
       "        [0.01694915, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.03389831, 0.        , 0.        , 0.        , 0.01694915],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.01694915, 0.01694915, 0.03389831],\n",
       "        [0.        , 0.01694915, 0.        , 0.01694915, 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.03389831, 0.01694915]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        , 0.03389831],\n",
       "        [0.03389831, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.01694915, 0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.01694915],\n",
       "        [0.        , 0.        , 0.03389831, 0.01694915, 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.01694915, 0.        ]]])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.zeros((m,n,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    Z[data.iloc[i, 1]-1, data.iloc[i, 0]-1, data.iloc[i, 2]-1] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zg = np.zeros((3,n,k))\n",
    "for g in range(3):\n",
    "    Zg[g,:,:] = np.mean(Z[groups==g,:,:],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(Zg == get_Zg(k, labels, groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2s, M3s = get_M(Zg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = 1,2,0\n",
    "Za = (Zg[c, :, :].T@Zg[b, :, :]/n)@np.linalg.inv(Zg[a, :, :].T @\n",
    "                                                 Zg[b, :, :]/n)@Zg[a, :, :].T\n",
    "Zb = (Zg[c, :, :].T@Zg[a, :, :]/n)@np.linalg.inv(Zg[b, :, :].T @\n",
    "                                                 Zg[a, :, :]/n)@Zg[b, :, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "M3 = np.einsum(\"ji,ki,li->jkl\", Za, Zb, Zg[c, :, :].T)/n\n",
    "M2 = Za@Zb.T/n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, vh = np.linalg.svd(M2, full_matrices=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  -9.19524314,   25.8762038 ,   59.94033902, -129.54118602,\n",
       "          15.06207194],\n",
       "       [ -13.53678217,   41.70697782,   56.48399218,   91.12466057,\n",
       "        -107.97827229],\n",
       "       [ -16.47236907,   42.96515193,  -22.52902475,   29.53756633,\n",
       "         206.2432776 ],\n",
       "       [ -20.49160929,   31.83289851,  -74.2551731 ,  -42.95577196,\n",
       "        -130.40987372],\n",
       "       [ -46.57817747,  -46.42863966,   12.38642101,    7.54231364,\n",
       "          12.84231721]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_whiten(M2, sym=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = u@np.diag(s**-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "M3_whiten = whiten_tensor(M3, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "M3_new = np.zeros((k,k,k))\n",
    "for a in range(k):\n",
    "    for b in range(k):\n",
    "        for c in range(k):\n",
    "            for d in range(k):\n",
    "                for e in range(k):\n",
    "                    for f in range(k):\n",
    "                        M3_new[a,b,c]+=M3[d,e,f]*Q[d,a]*Q[e,b]*Q[f,c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, vectors = robust_tensor_power(M3_whiten, 20, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(M3_new,M3_whiten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "M3_2 = np.zeros((k,k,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i1 in range(k):\n",
    "    for i2 in range(k):\n",
    "        for i3 in range(k):\n",
    "            M3_2[i1, i2, i3] = np.sum(Za[i1,:]*Zb[i2,:]*Zg[c,:,i3])/n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.06549972e-06, 4.00909567e-07, 1.86179973e-07, 6.24276453e-08,\n",
       "         1.03600769e-07],\n",
       "        [2.54174415e-07, 4.46648428e-07, 1.40646002e-07, 7.01520550e-08,\n",
       "         1.77188614e-07],\n",
       "        [2.36062713e-07, 1.11559407e-07, 1.74379658e-07, 1.00333511e-07,\n",
       "         1.17523448e-07],\n",
       "        [5.52842310e-08, 6.02824313e-08, 1.31176047e-07, 2.14339296e-08,\n",
       "         7.79550528e-08],\n",
       "        [5.39319191e-08, 1.07918096e-07, 1.30878074e-07, 1.41321823e-07,\n",
       "         2.78167546e-07]],\n",
       "\n",
       "       [[3.37570139e-07, 3.50205452e-07, 1.47750442e-07, 1.00946691e-07,\n",
       "         1.26257788e-07],\n",
       "        [3.57496434e-07, 1.13783132e-06, 5.66940033e-07, 2.62104108e-07,\n",
       "         1.53713051e-07],\n",
       "        [1.10026953e-07, 4.33278892e-07, 4.48427205e-07, 2.72991611e-07,\n",
       "         1.78693951e-07],\n",
       "        [8.98954393e-08, 2.25697396e-07, 1.88496372e-07, 1.36317728e-07,\n",
       "         1.52921146e-07],\n",
       "        [1.52980207e-07, 2.17240718e-07, 1.19820034e-07, 7.11922876e-08,\n",
       "         3.12528959e-07]],\n",
       "\n",
       "       [[2.44006157e-07, 1.35243275e-07, 1.44389508e-07, 4.85001613e-08,\n",
       "         4.87087517e-08],\n",
       "        [1.59893936e-07, 4.40450765e-07, 3.65228816e-07, 1.88416711e-07,\n",
       "         1.76596496e-07],\n",
       "        [1.09033484e-07, 3.90103747e-07, 7.87254398e-07, 4.77715503e-07,\n",
       "         3.44741063e-07],\n",
       "        [3.92610934e-08, 1.57279260e-07, 4.65636352e-07, 5.85014882e-07,\n",
       "         3.10968438e-07],\n",
       "        [8.05523185e-08, 1.89509142e-07, 2.90166576e-07, 3.34692889e-07,\n",
       "         2.52088181e-07]],\n",
       "\n",
       "       [[1.82479613e-07, 5.52964522e-08, 8.64269612e-08, 1.21447680e-07,\n",
       "         5.62929416e-08],\n",
       "        [8.93711627e-08, 1.55436007e-07, 2.46465419e-07, 1.36729535e-07,\n",
       "         1.15085406e-07],\n",
       "        [9.83605918e-08, 2.22279437e-07, 6.34369759e-07, 6.60193791e-07,\n",
       "         3.21002366e-07],\n",
       "        [2.21681110e-08, 1.52178391e-07, 6.60717903e-07, 1.34564648e-06,\n",
       "         5.87137211e-07],\n",
       "        [4.11254700e-08, 2.17025390e-07, 2.79699965e-07, 5.15504860e-07,\n",
       "         6.81026550e-07]],\n",
       "\n",
       "       [[2.13093514e-07, 1.13470039e-07, 6.05114095e-08, 5.36208650e-08,\n",
       "         3.84031744e-07],\n",
       "        [1.69595916e-07, 2.35682663e-07, 1.18941793e-07, 1.16724481e-07,\n",
       "         5.31072828e-07],\n",
       "        [1.17926788e-07, 2.29805946e-07, 4.01620150e-07, 3.42351459e-07,\n",
       "         4.35843810e-07],\n",
       "        [4.28772693e-08, 1.12150653e-07, 3.32473715e-07, 7.16126899e-07,\n",
       "         7.91395826e-07],\n",
       "        [1.96791756e-07, 2.44397020e-07, 2.87458356e-07, 6.81486265e-07,\n",
       "         6.34125990e-06]]])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M3_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.06549972e-06, 4.00909567e-07, 1.86179973e-07, 6.24276453e-08,\n",
       "         1.03600769e-07],\n",
       "        [2.54174415e-07, 4.46648428e-07, 1.40646002e-07, 7.01520550e-08,\n",
       "         1.77188614e-07],\n",
       "        [2.36062713e-07, 1.11559407e-07, 1.74379658e-07, 1.00333511e-07,\n",
       "         1.17523448e-07],\n",
       "        [5.52842310e-08, 6.02824313e-08, 1.31176047e-07, 2.14339296e-08,\n",
       "         7.79550528e-08],\n",
       "        [5.39319191e-08, 1.07918096e-07, 1.30878074e-07, 1.41321823e-07,\n",
       "         2.78167546e-07]],\n",
       "\n",
       "       [[3.37570139e-07, 3.50205452e-07, 1.47750442e-07, 1.00946691e-07,\n",
       "         1.26257788e-07],\n",
       "        [3.57496434e-07, 1.13783132e-06, 5.66940033e-07, 2.62104108e-07,\n",
       "         1.53713051e-07],\n",
       "        [1.10026953e-07, 4.33278892e-07, 4.48427205e-07, 2.72991611e-07,\n",
       "         1.78693951e-07],\n",
       "        [8.98954393e-08, 2.25697396e-07, 1.88496372e-07, 1.36317728e-07,\n",
       "         1.52921146e-07],\n",
       "        [1.52980207e-07, 2.17240718e-07, 1.19820034e-07, 7.11922876e-08,\n",
       "         3.12528959e-07]],\n",
       "\n",
       "       [[2.44006157e-07, 1.35243275e-07, 1.44389508e-07, 4.85001613e-08,\n",
       "         4.87087517e-08],\n",
       "        [1.59893936e-07, 4.40450765e-07, 3.65228816e-07, 1.88416711e-07,\n",
       "         1.76596496e-07],\n",
       "        [1.09033484e-07, 3.90103747e-07, 7.87254398e-07, 4.77715503e-07,\n",
       "         3.44741063e-07],\n",
       "        [3.92610934e-08, 1.57279260e-07, 4.65636352e-07, 5.85014882e-07,\n",
       "         3.10968438e-07],\n",
       "        [8.05523185e-08, 1.89509142e-07, 2.90166576e-07, 3.34692889e-07,\n",
       "         2.52088181e-07]],\n",
       "\n",
       "       [[1.82479613e-07, 5.52964522e-08, 8.64269612e-08, 1.21447680e-07,\n",
       "         5.62929416e-08],\n",
       "        [8.93711627e-08, 1.55436007e-07, 2.46465419e-07, 1.36729535e-07,\n",
       "         1.15085406e-07],\n",
       "        [9.83605918e-08, 2.22279437e-07, 6.34369759e-07, 6.60193791e-07,\n",
       "         3.21002366e-07],\n",
       "        [2.21681110e-08, 1.52178391e-07, 6.60717903e-07, 1.34564648e-06,\n",
       "         5.87137211e-07],\n",
       "        [4.11254700e-08, 2.17025390e-07, 2.79699965e-07, 5.15504860e-07,\n",
       "         6.81026550e-07]],\n",
       "\n",
       "       [[2.13093514e-07, 1.13470039e-07, 6.05114095e-08, 5.36208650e-08,\n",
       "         3.84031744e-07],\n",
       "        [1.69595916e-07, 2.35682663e-07, 1.18941793e-07, 1.16724481e-07,\n",
       "         5.31072828e-07],\n",
       "        [1.17926788e-07, 2.29805946e-07, 4.01620150e-07, 3.42351459e-07,\n",
       "         4.35843810e-07],\n",
       "        [4.28772693e-08, 1.12150653e-07, 3.32473715e-07, 7.16126899e-07,\n",
       "         7.91395826e-07],\n",
       "        [1.96791756e-07, 2.44397020e-07, 2.87458356e-07, 6.81486265e-07,\n",
       "         6.34125990e-06]]])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_tensor_power(T, L=20, N=100, sym=True):\n",
    "    k, _, _ = T.shape\n",
    "    if sym:\n",
    "        T = sym_tensor(T)\n",
    "    values = np.zeros(k)\n",
    "    vectors = np.zeros((k, k))\n",
    "    for h in range(k):\n",
    "        theta_tau = []\n",
    "        for tau in range(L):\n",
    "            theta = np.random.randn(k)\n",
    "            theta /= np.linalg.norm(theta)\n",
    "            for t in range(N):\n",
    "                theta = np.einsum(\"aef,e,f->a\", T, theta, theta)\n",
    "                theta /= np.linalg.norm(theta)\n",
    "            theta_tau.append(theta)\n",
    "\n",
    "        lam_best = float(\"-Inf\")\n",
    "        theta_best = np.array([])\n",
    "        for theta in theta_tau:\n",
    "            lam = np.einsum(\"efg,e,f,g->\", T, theta, theta, theta)\n",
    "            if lam > lam_best:\n",
    "                lam_best = lam\n",
    "                theta_best = theta\n",
    "\n",
    "        theta = theta_best\n",
    "        for t in range(N):\n",
    "            theta = np.einsum(\"aef,e,f->a\", T, theta, theta)\n",
    "            theta /= np.linalg.norm(theta)\n",
    "        lam = np.einsum(\"efg,e,f,g->\", T, theta, theta, theta)\n",
    "\n",
    "        values[h] = lam\n",
    "        vectors[:, h] = theta\n",
    "        T = T-lam*np.einsum(\"a,b,c->abc\", theta, theta, theta)\n",
    "    return values, vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam, vec = robust_tensor_power(M3_whiten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = sym_tensor(M3_whiten)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam, vec = robust_tensor_power(T, L = 20,N=100, sym=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.zeros((k, k, k))\n",
    "for i in range(k):\n",
    "    temp += lam[i]*np.einsum(\"a,b,c->abc\", vec[:, i], vec[:, i], vec[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03568052611212279"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(temp-T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.linalg.inv(Q.T)@vec@np.diag(lam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(k, labels, groups=None, sym=True,cutoff=1e-7, L=20, N=100, seed=0):\n",
    "    m, n = labels.shape\n",
    "    if groups is None:\n",
    "        np.random.seed(seed)\n",
    "        groups = np.random.randint(3, size=m)\n",
    "    Zg = get_Zg(k, labels, groups)\n",
    "    M2s, M3s = get_M(Zg)\n",
    "    Cc = np.zeros((3, k, k))\n",
    "    W = np.zeros((3, k, k))\n",
    "    for g, (M2, M3) in enumerate(zip(M2s, M3s)):\n",
    "        Q = get_whiten(M2, sym)\n",
    "        M3_whiten = whiten_tensor(M3, Q)\n",
    "        values, vectors = robust_tensor_power(M3_whiten, L, N, sym)\n",
    "        w = values**-2\n",
    "        mu = np.linalg.inv(Q.T)@vectors@np.diag(values)\n",
    "        best = np.argmax(mu, axis=0)\n",
    "        for h in range(k):\n",
    "            Cc[g, :, best[h]] = mu[:, h]\n",
    "            W[g, best[h], best[h]] = w[h]\n",
    "    W = np.mean(W, axis=0)\n",
    "    C = np.zeros((m, k, k))\n",
    "    for i in range(m):\n",
    "        Ca = (np.sum(Cc, axis=0)-Cc[groups[i], :, :])/2\n",
    "        Za = (np.sum(Zg, axis=0)-Zg[groups[i], :, :])/2\n",
    "        E = np.zeros((k, k))\n",
    "        for j in range(n):\n",
    "            if labels[i,j]!=-1:\n",
    "                E[labels[i, j], :] += Za[j, :]\n",
    "        E /= n\n",
    "        Ci = E@np.linalg.inv(W@Ca.T)\n",
    "        if cutoff:\n",
    "            Ci[Ci < cutoff] = cutoff\n",
    "        colsums = np.sum(Ci, axis=0)\n",
    "        Ci /= colsums[np.newaxis, :]\n",
    "        C[i, :, :] = Ci\n",
    "    return C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_estimated = get_confusion_matrix(k, labels, groups=groups, sym=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 4, 3], dtype=int64)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(mu,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu0 = lam[0]*np.linalg.inv(Q.T)@vec[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = -np.eye(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "E[E<0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., -0., -0., -0., -0.],\n",
       "       [-0.,  0., -0., -0., -0.],\n",
       "       [-0., -0.,  0., -0., -0.],\n",
       "       [-0., -0., -0.,  0., -0.],\n",
       "       [-0., -0., -0., -0.,  0.]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(mu0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.47221395, 1.9597989 , 1.68658776, 1.62258932, 1.5157169 ]),\n",
       " array([[-0.20816801, -0.45904245, -0.28248499, -0.78507705, -0.44330809],\n",
       "        [ 0.34572185,  0.49387216,  0.52550452, -0.60544145,  0.20886257],\n",
       "        [ 0.44722585, -0.25200777,  0.59235523,  0.1237719 , -0.73952102],\n",
       "        [-0.78471769,  0.16964156,  0.39568989,  0.03355718, -0.24202772],\n",
       "        [ 0.14611525,  0.67311525, -0.36958358, -0.02547738, -0.39291933]]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robust_tensor_power(temp,sym=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.46460466, 1.95134792, 1.69621225, 1.61947364, 1.52595186]),\n",
       " array([[-0.19890427, -0.44754347, -0.27192651, -0.7790689 , -0.44857849],\n",
       "        [ 0.33327075,  0.49026603,  0.52012714, -0.61032911,  0.20734864],\n",
       "        [ 0.44301318, -0.23003884,  0.60929923,  0.1369673 , -0.7439836 ],\n",
       "        [-0.79524795,  0.1743316 ,  0.39476733,  0.03790537, -0.24151606],\n",
       "        [ 0.14383224,  0.68995267, -0.35838099, -0.01879279, -0.37939724]]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robust_tensor_power(M3_whiten,sym=False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b4b4feff2f24a0f0a34464dbe537a36fda679851528fb8735cb41fa49dffb2d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
